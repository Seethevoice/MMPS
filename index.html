<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
        margin: 0.4em;
    }

    p {
        margin: 0.2em;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        margin: 0;
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
    <head>
        <title>MMPS-Net</title>
    </head>

    <body>
	    
        <br>
        <center>
            <span style="font-size:42px">Multi-candidate Motion Modeling for 3D Human Pose and Shape Estimation from Monocular Video</span>
        </center>
        <br>
	<table align=center width=900px></table>
	    <center><h1>Abstract</h1></center>
            <tr>	
                <td width=600px>
                    <br>
                    <p align="justify" style="font-size: 18px">
                        Estimating 3D human pose and shape from monocular video is an ill-posed problem due to depth ambiguity. Yet, most existing methods overlook the potential multiple motion hypotheses arising from this ambiguity. To tackle this, we propose a multi-candidate motion pose and shape network (MMPS-Net), which is designed to generate temporal representations of multiple plausible motion candidates and yield their adaptive fusion for 3D human pose and shape estimation. Specifically, we first propose a multi-candidate motion continuity attention (MMoCA) module to generate multiple kinematically compliant motion candidates. Second, we introduce a multi-candidate cross-attention (MCA) module to enable information passing among candidates to strengthen their relevance. Third, we develop a multi-candidate hierarchical attentive feature integration (MHAFI) module to refine the target frame’s feature representation by capturing temporal correlations within each motion candidate and adaptively integrating all candidates. By coupling these designs, MMPS-Net surpasses video-based methods on the 3DPW, MPI-INF-3DHP, and Human3.6M benchmarks.
		    </p> 
	        </td>
	    </tr>
        <br>

	
	    
	<!--
        <br>
        <table align=center width=700px>
            	<tr> 
                    <td align=center width=100px>
        		<center>
        			<span style="font-size:20px"><a href="https://dblp.org/pid/09/10143.html">Wen-Li Wei *</a></span>
        		</center>
        	    </td>

        	    <td align=center width=100px>
        		<center>
        			<span style="font-size:20px"><a href="https://sites.google.com/site/jenchunlin/">Jen-Chun Lin *</a></span>    
        		</center>
        	    </td>

        	    <td align=center width=100px>
        		<center>
        			<span style="font-size:20px"><a href="https://homepage.iis.sinica.edu.tw/pages/liutyng/index_en.html">Tyng-Luh Liu </a></span>
        		</center>
        	    </td>

        	    <td align=center width=100px>
        		<center>
        			<span style="font-size:20px"><a href="https://homepage.iis.sinica.edu.tw/pages/liao/index_en.html">Hong-Yuan Mark Liao </a></span>
        		</center>
        	    </td>       
     	        </tr>
    	</table>
	
        <br>
        <table align=center width=700px>
        	<tr>
              		<td align=center width=100px>
            			<center>
	    				<span style="font-size:20px">
		    				* authors contributed equally
		    				<br><br> 
                    				Academia Sinica, Taiwan
						<br><br> 
						<a href="https://arxiv.org/abs/2203.08534">[Paper]</a> <a href="https://github.com/MPS-Net/MPS-Net_release">[Code]</a>
            				</span>
            			</center>
        		</td>
     		</tr>
    	</table>  
	
        <br>	    
    	<table align=center width=700px>
       		<tr>
        		<td align=center width=100px>  
        		</td>
     		</tr>
    	</table>
        <br>
        <table align=center width=900px>
            	<tr>
	        	<td>
                    		<center>                      
		        		<img src = "./Fig3.png" width="1080px"></img>
                        		<span style="font-size:15px;font-style:italic">    Overview of our motion pose and shape network (MPS-Net). MPS-Net estimates pose, shape, and camera parameters Θ in the video sequence based on the static feature extractor, temporal encoder, temporal feature integration, and SMPL parameter regressor to generate 3D human pose and shape.</span>
                    		</center>
                	</td> 
	    	</tr>
        </table>

    	<table align=center width=900px></table>
            <tr>
                <td width=600px>
                    <br>
                    <p align="justify" style="font-size: 18px">
                        Learning to capture human motion is essential to 3D human pose and shape estimation from monocular video. However, the existing methods mainly rely on recurrent or convolutional operation to model such temporal information, which limits the ability to capture non-local context relations of human motion. To address this problem, we propose a motion pose and shape network (MPS-Net) to effectively capture humans in motion to estimate accurate and temporally coherent 3D human pose and shape from a video. Specifically, we first propose a motion continuity attention (MoCA) module that leverages visual cues observed from human motion to adaptively recalibrate the range that needs attention in the sequence to better capture the motion continuity dependencies. Then, we develop a hierarchical attentive feature integration (HAFI) module to effectively combine adjacent past and future feature representations to strengthen temporal correlation and refine the feature representation of the current frame. By coupling the MoCA and HAFI modules, the proposed MPS-Net excels in estimating 3D human pose and shape in the video. Though conceptually simple, our MPS-Net not only outperforms the state-of-the-art methods on the 3DPW, MPI-INF-3DHP, and Human3.6M benchmark datasets, but also uses fewer network parameters.
		    </p> 
	        </td>
	    </tr>
	<br>
        <table align=center width=900px>
            <tr>
                <td colspan='2'>
                    <center>
                        <img src = "./360.gif" width="450px" height="253px"></img>
                    </center>     
	        </td>

                <td colspan='2'>			
                    <center>
		        <img src = "./MPS_Net_DM3-choice_output.gif" width="450px" height="127px"></img>
		    </center>
		    <center>
                        <a href="./MPS_Net_201911_output.mp4">
                            <video width="450" controls preload>
                                <source src="./MPS_Net_201911_output.mp4" type="video/mp4">
                            </video>
                        </a>
                    </center>
		</td> 
            </tr>
        </table>

        <center>
	    <span style="font-size:14px">   Left: The video shows the 3D human pose and shape estimation results of our MPS-Net from different viewpoints. Top-Right: Visual results of the continuity of human motion learned by MPS-Net (MPS-Net produces a transition effect between pose exchanges). Bottom-Right: Visualization of a standing still person by MPS-Net. When the input video content is a person standing still, MPS-Net does not force the subject to be in motion. </span>
 	</center>
        <br><br>   
	<hr>
        <table align=center width=700>
            <center><h1>Paper</h1></center>
            <tr>
	        <td>
		    <a href="https://arxiv.org/abs/2203.08534"><img class="layered-paper-big" style="height:175px" src="./paperCover.png"/></a>
		</td>
                <td> 
		    <span style="font-size:18px">
		    </span>                                                                   
		    <br><br>		
			<span style="font-size:18px"><a href="https://arxiv.org/abs/2203.08534">[Paper] </a> CVPR 2022 </span> 
		    <br><br>
	            <br><br>   
			<span style="font-size:18px"><a href="https://github.com/MPS-Net/MPS-Net_release/">[Code] </a> </span> 
                </td>
            </tr>
            <tr>
                <td colspan="5" style="font-size: 14px">
                </td>
            </tr>
            <tr>
                <td>
                    &nbsp;
                </td>
            </tr>
        </table>
	-->        
        <br>
        <hr>            
        <table align=center width=900px>
            <center><h1>Demo</h1></center>
            <tr>
		<center>
                    <a href="./R2.mp4">
                        <video width="900" controls preload>
                            <source src="./R2.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>
		<center>
                    <a href="./demo2.mp4">
                        <video width="900" controls preload>
                            <source src="./demo2.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>
		<center>
                    <a href="./R7.mp4">
                        <video width="900" controls preload>
                            <source src="./R7.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>
		<center>
                    <a href="./R3.mp4">
                        <video width="900" controls preload>
                            <source src="./R3.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>
		    
		
		<center>
                    <a href="./R6.mp4">
                        <video width="900" controls preload>
                            <source src="./R6.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>
		
		<center>
                    <a href="./R1.mp4">
                        <video width="900" controls preload>
                            <source src="./R1.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>
				
					            		
					
		
		<center>
                    <a href="./R8.mp4">
                        <video width="900" controls preload>
                            <source src="./R8.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>		
		<center>
                    <a href="./R4.mp4">
                        <video width="900" controls preload>
                            <source src="./R4.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>
		   
		<center>
                    <a href="./demo1.mp4">
                        <video width="900" controls preload>
                            <source src="./demo1.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>
            </tr>
        </table>   
                     
	<br>
        <hr>
        <center><h1>Qualitative comparison</h1></center>
             <tr>
                 <th colspan='4'>
                   <center>
                     <span style="font-size:22px">Qualitative comparison on 3DPW</span>
                   </center>
                 </th>
             </tr>
        	<tr>
			<center>
                    <a href="./3DPW.mp4">
                        <video width="900" controls preload>
                            <source src="./3DPW.mp4" type="video/mp4">
                        </video>
                    </a><br>	
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center><br>
		</tr>              

	        		
		<br>
	    <tr>
                 <th colspan='4'>
                   <center>
                     <span style="font-size:22px">Qualitative comparison on mpii3d</span>
                   </center>
                 </th>
             </tr>
	    <!--<center><h1>Qualitative comparison on mpii3d</h1></center>-->
            <tr>
                <center>
                    <a href="./mpii3d.mp4">
                        <video width="900" controls preload>
                            <source src="./mpii3d.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center>
		<br>
	    <tr>
                 <th colspan='4'>
                   <center>
                     <span style="font-size:22px">Qualitative comparison on Human3.6M</span>
                   </center>
                 </th>
             </tr>
	    <!--<center><h1>Qualitative comparison on Human3.6M</h1></center>-->
            <tr>
                <center>
                    <a href="./Human36M.mp4">
                        <video width="900" controls preload>
                            <source src="./Human36M.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <!--<span style="font-size:16px"> Original video frame rate: 25fps </span>-->
                </center> 
		<br>
	    </tr>
            <br>
	    <tr>
                <td>
                    &nbsp;
                    <!--you just need a space in a row-->
                </td>
            </tr>
	   
	      <tr>
                  <td>
                      &nbsp;
                      <!--you just need a space in a row-->
                  </td>
              </tr>		  
        </table>
    </body>
</html>
